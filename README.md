# chat-code-interpreter

This repository contains a Python-based Chat Code-Interpreter application that leverages OpenAI's GPT-3.5-turbo model for generating Python code and executing it on user-uploaded CSV data. The user interacts with the app via Chainlit, a framework for creating interactive conversational UIs.

## Problem Statement

The application allows users to upload `.csv` files and send queries. Based on the user query, the assistant generates Python code to analyze the uploaded data (CSV) and returns the result. The assistant can also handle general chit-chat or non-technical conversations. The assistant executes the generated Python code in a safe and controlled environment and returns the results.

Key features:
- CSV file handling and processing.
- Dynamic code generation using OpenAI API.
- Safe code execution based on user queries.
- Simple Chainlit-based conversational UI.
- General Chit-Chat: The assistant can also engage in general conversation, responding to user messages.


## Requirements

Before running this project locally or deploying it, ensure you have the following dependencies:

### 1. Python 3.8+ (recommended)

### 2. Required Python Libraries

Install the required Python packages via `requirements.txt`.

```bash
pip install -r requirements.txt
```

### 3. OpenAI API Key

You must set your OpenAI API key to run the code generation functionality. Ensure you have a valid API key from [OpenAI](https://openai.com/).

To configure the API key, set the `OPENAI_API_KEY` as an environment variable. For example:

- On macOS/Linux:
  ```bash
  export OPENAI_API_KEY="your-api-key"
  ```
- On Windows (Command Prompt):
  ```cmd
  set OPENAI_API_KEY=your-api-key
  ```

## How to Run the Application

### 1. Locally (via Python)

After setting up the environment and installing dependencies, you can run the Chainlit app locally:

```bash
chainlit run app.py
```

The application will be available at [http://localhost:8000](http://localhost:8000).

### 2. Docker (Optional)

You can also run the application inside a Docker container. First, build the Docker image:

```bash
docker build -t chat-code-interpreter .
```

Then, run the container:

```bash
docker run -e OPENAI_API_KEY="your-api-key" -p 8000:8000 chat-code-interpreter
```

The application will be accessible at [http://localhost:8000](http://localhost:8000).

## How the Application Works

### 1. User Interaction

- **CSV File Upload**: The user uploads a `.csv` file.
- **Query Submission**: The user can submit a query based on the uploaded CSV data (e.g., "What is the average of column X?").
- **Code Generation**: OpenAI's GPT-3.5-turbo model generates Python code to analyze the CSV data based on the query.
- **Code Execution**: The generated code is executed using the pandas library to process the data.
- **Result Display**: The result of the code execution is displayed back to the user.

### 2. Example Queries

- "What is the mean of column 'age'?"
- "Generate a plot for the 'sales' column over time."
- "Find the top 5 rows based on column 'revenue'."

### 3. General Chit-chat

The assistant also handles general chit-chat. If the user doesn't provide a query or request a CSV analysis, the assistant can converse on a variety of topics.

## Key Technologies

- **OpenAI GPT-3.5-turbo**: For code generation and conversation handling.
- **Chainlit**: For building the conversational UI and handling user messages.
- **Pandas**: For processing and analyzing CSV data.
- **Python**: The primary language for the backend logic.

## Key Functions Implemented

1. **`handle_message()`**: Handles user messages, processes file uploads, and generates responses. It checks if the message contains a CSV file and calls the appropriate functions for further processing.

2. **`process_query()`**: Generates Python code using OpenAI's GPT-3.5-turbo model based on the user's query. The generated code is then executed in a controlled environment, and the result is returned.

3. **`execute_code()`**: Safely executes the Python code generated by the assistant and processes the result using the pandas library for CSV data analysis.

## Docker Instructions

To containerize this application, a `Dockerfile` is included in the repository. It sets up the necessary environment and dependencies.

### Steps to Run in Docker:

1. Build the Docker image:

   ```bash
   docker build -t chat-code-interpreter .
   ```

2. Run the Docker container:

   ```bash
   docker run -e OPENAI_API_KEY="your-api-key" -p 8000:8000 chat-code-interpreter
   ```

### Docker Setup:

The Docker container exposes the app on port `8000` by default. When running the container, the `OPENAI_API_KEY` must be provided as an environment variable.


## Folder Structure

```
chat-code-interpreter/
│
├── app.py                     # Main Chainlit app file to handle user interactions.
├── Dockerfile                 # Docker configuration to containerize the app.
├── requirements.txt           # Python dependencies.
├── README.md                  # Project documentation.
└── sample.csv/                # Sample CSV file.
```

### Folder Explanation:

- **`app.py`**: The main script for running the Chainlit application. This file handles user interactions, including file uploads and processing of queries.
- **`Dockerfile`**: Contains the instructions to build the Docker image for this application.
- **`requirements.txt`**: Lists the Python packages required to run the application.
- **`README.md`**: Documentation for setting up and using the project.

### Example
<img width="883" alt="image" src="https://github.com/user-attachments/assets/2c89900e-5cf4-48f5-866c-5cf02db4f981" />
<img width="940" alt="image" src="https://github.com/user-attachments/assets/0047f7bf-876b-4ebb-8afa-dc0485fd19c8" />

